% Chapter containing details about the hysteresis of the muscle
% Outline:
% - Introduction
% - Evolutionary algorithms outline
%	- Genetic Algorithm
% - Multi-variable optimization
% 	- Firefly Algorithm
% 	- Modified Firefly Algorithm
% 	- PSO
% - Implementation
% - Results comparison

\chapter{Hysteresis Parameter Optimization}
\label{ch:optimization}

In this chapter, the methods to obtain the model's parameters are explained.
Section~\ref{sec:5.evo} introduces the concept of \textit{evolutionary algorithm},
with particular regard towards a simple genetic algorithm approach
with the purpose of optimization.

After that, Section~\ref{sec:5.opt} introduces methods of \textit{multi-variable
optimization}, with the goal of transforming the search of parameters
into an optimization problem.

Section~\ref{sec:5.impl} describes the implementation of said algorithms,
and Section~\ref{sec:5.res} shows the result for each of them.

%{\color{red} 
%\begin{itemize}
%	\item Introduzione
%	\item Algoritmi evoluzionistici
%	\begin{itemize}
%		\item Algoritmi genetici
%	\end{itemize}
%	\item Ottimizzazione multi variabile
%	\begin{itemize}
%		\item Algoritmo firefly
%		\item Algoritmo firefly modificato
%		\item Particle Swarm Optimization
%	\end{itemize}
%	\item Implementazione
%	\item Confronto risultati
%\end{itemize}
%}

\section{Introduction}
After having described how to get a discrete model of the McKibben artificial muscle,
the Bouc-Wen model of hysteresis has been introduced.
This model proves useful to describe a hysteretic behaviour in a simple manner,
and can provide great advantages in terms of performance when it comes to control.

However, there are parameters that have to be tuned in order for the model
to operate correctly. The tuning may be done by trial and error, or the whole process
may be automated.

The parameter refinement process makes use of an algorithm to
find the parameters of the Bouc-Wen model that give a best approximation
of the real experimental data. Such algorithms include, but are not limited to,
Recursive Least Squares (RLS), evolutionary algorithms
and multi-variable optimization algorithms.

For this work, different approaches based on evolutionary algorithms
and multi-variable optimization methods have been tested.

%\clearpage

\section{Evolutionary Algorithms}
\label{sec:5.evo}

An evolutionary algorithm is a population-based optimization algorithm
that mimics the behaviour of biological evolution, simulating the steps of
reproduction, mutation, recombination and selection.

Each individual is tested in an optimization problem,
and the best characteristic of the population are passed through the generations.
The evaluation of an individual is done by means of a fitness function.
A fitness function is a operator that assigns a fitness value to each individual.
Depending on the nature of the problem, individuals with lower (or higher)
fitness values are judged "better" from the algorithm and have a higher probability
of being chosen in the mating step to generate new, better individuals.
Therefore, their characteristics have a higher chance to be passed onto next generations
in order to iteratively refine the parameters and arrive at a acceptable solution.

After a certain amount of generations, or after one individual reaches
a fixed fit value, the algorithm stops and the best individual is chosen
as the solution to the optimization problem.

\subsection{Genetic Algorithm}

A genetic algorithm (GA)~\cite{fleming2001genetic} is a kind of evolutionary algorithm inspired
by the concept of natural selection that permeates a biological evolutionary process.

Genetic algorithms are a class of stochastic global search algorithm
operating on a set called \textit{population} of current approximations,
called \textit{individuals}.
Individuals are encoded as a set (\textit{chromosome}) of parameters (\textit{genes}).

Once a population has been created, each individual performance is assessed
according to the objective function characterising the problem that has to be solved.

Algorithms belonging to this class are divided into the following steps:
\textit{initialization}, \textit{evaluation}, \textit{crossover} and \textit{mutation}.
The description and peculiarities of each step are discussed in Section~\ref{sec:5.steps}.
The genetic algorithm also makes use of several parameters, which are summarized
in Table~\ref{tab:ga_params}.

\begin{table}[]
	\centering
	\begin{tabularx}{\linewidth}{c X}
		\toprule
		\textbf{Parameter} & \textbf{Description} \\ \midrule
		$pop\_size$        & The population's size, i.e. the number of individuals (candidate solutions) that evolve to find a good approximation. \\
		$max\_gen$         & The maximum generation. After reaching that stage of evolution, the algorithm stops. \\
		$d$           	   & The chromosome's dimension, i.e. the number of variables to be optimized by the algorithm. \\
		$L$           	   & A $d$-dimensional vector containing the lower bounds for each variable. \\
		$U$				   & A $d$-dimensional vector containing the upper bounds for each variable. \\
		$p_{cross}$		   & The crossover probability. It controls the chance of inheriting a chromosome from a specific parent with respect to the other. \\
		$p_{mut}$		   & The mutation probability. \\
		$m_m$			   & The mutation magnitude, i.e. how much a given chromosome changes in the event of a mutation. \\ \bottomrule
	\end{tabularx}
	\caption{Parameters for the genetic algorithm}
	\label{tab:ga_params}
\end{table}

\subsection{Algorithm Overview}

\subsection{Algorithm Steps}
\label{sec:5.steps}
\subsubsection{Initialization Step}

For a genetic algorithm, the initialization step consists in the creation
of the individuals, and by extension that of the population.

One of the most common initialization methods is random initialization:
each gene of any individual is randomly chosen between a defined interval.
This gives a higher chance of finding good results from the first generations,
and refine the solution starting from them.

Another initialization method may be to create a population of equal
individuals, and mainly rely on mutation for the first generations
in order to find better approximations. This method, while it may better
reflect the natural behaviour of a biological evolutionary process,
takes also a much larger number of generations to return appreciable results.

For this reason, the GA developed for this work makes use of random initialization.


\subsubsection{Evaluation Step}

The evaluation step concerns assessing a fitness value to each individual
in order to rank them according to their performance in solving the optimization problem.
The fitness value is assigned to each individual by means of a \textit{fitness function}.

Experimental input pressure and output displacement,
respectively described in Equations~\ref{eq:exp_pres} and~\ref{eq:exp_disp},
are taken from data acquired by the identification experiments described
in Section~\ref{sec:4.ide}. 

\begin{align}
u &= \left[u_1,u_2,\textellipsis,u_k\right] \label{eq:exp_pres} \\
l &= \left[l_1,l_2,\textellipsis,l_k\right] \label{eq:exp_disp}
\end{align}

with $k$ representing the number of points 
for which the experimental data has been sampled.

Each individual is used to perform a specific simulation of the model with its genes
set as Bouc-Wen hysteresis parameters, using $u$ as input.
The simulated output displacement $\hat{l}$
is then compared to the experimental displacement $l$.

The fitness function chosen for this step is described in Equation~\ref{eq:fitness}.
This function returns the fitness value for the i-th individual of the population.

\begin{align}
fit(i) = -\frac{1}{\sum_{i=1}^k{\left(l_i-\hat{l}_i\right)^2}}
\label{eq:fitness}
\end{align}

Judging from the nature of the fitness function, it is clear that
individuals with a fitness value close to 0 are better than others,
as it means that their simulated output is close to experimental data.



